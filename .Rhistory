'hotmail.com',
'icloud.com',
'yahoo.com',
'mail.com',
'att.net',
'bellsouth.net',
'charter.net',
'comcast.net',
"msn.com",
'gmail.co',
'outlook.com',
'verizon.net',
'ymail.com',
'me.com',
'aeneas.net')
siteDf <- subset(comReport, !(tolower(Site_Key) %in% pubSites))[c("Site_Key","Organization Name")]
siteDf <- distinct(siteDf)
for (i in 1:nrow(siteDf)){
url <- paste('http://www.', siteDf[i, 'Site_Key'], sep='')
test <- HEAD(url)
if (test$status_code==200){
webpage <- read_html(url)
siteDf[i, 'htitle'] <- webpage %>%
html_node("title") %>%
html_text()}
}
test <- HEAD(url)
test <- http_error(url)
test <- url_success(url)
test <- !http_error(url)
.libPaths( c("C:/R/Packages", .libPaths()) )
library(tid)
library(tidyverse)
tidyverse_update()
install.packages(c("dplyr", "purrr", "rlang", "tidyr"))
install.packages(c("dplyr", "purrr", "rlang", "tidyr"))
.libPaths( c("C:/R/Packages", .libPaths()) )
install.packages("stm", lib="C:/R/Packages")
install.packages("quanteda", lib="C:/R/Packages")
.libPaths( c("C:/R/Packages", .libPaths()) )
setwd("C:/Users/P6BQ/Desktop/capstone.arthur.pignotti") #local location of github repo
commentsDf <- read.csv("Data/commentsDf.csv", stringsAsFactors = FALSE)
library(dplyr)
library(stringr)
library(ggplot2)
library(tidytext)
library(tidyr)
data(stop_words)
test <- commentsDf %>%
group_by(Document.ID) %>%
mutate(linenumber = row_number()) %>%
ungroup()
test1 <- test %>%
unnest_tokens(word, Text)
#######################
# Bigram Testing      #
#######################
test1 <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
unite(bigram, word1, word2, sep = " ")
bigram_tf_idf <- test1 %>%
count(book, bigram) %>%
bind_tf_idf(bigram, book, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf <- test1 %>%
count(Document.ID, bigram) %>%
bind_tf_idf(bigram, Document.ID, n) %>%
arrange(desc(tf_idf))
View(test1)
#######################
# Bigram Testing      #
#######################
test1 <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(Document.ID, word1, word2, sort = TRUE) %>%
unite(bigram, word1, word2, sep = " ")
bigram_tf_idf <- test1 %>%
count(Document.ID, bigram) %>%
bind_tf_idf(bigram, Document.ID, n) %>%
arrange(desc(tf_idf))
View(test1)
bigram_tf_idf <- test1 %>%
#count(Document.ID, bigram) %>%
bind_tf_idf(bigram, Document.ID, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
#######################
# Bigram Testing      #
#######################
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(Document.ID, word1, word2, sort = TRUE) %>%
unite(bigram, word1, word2, sep = " ")
bigram_total <- bigram_count %>%
group_by(Document.ID) %>%
summarize(total = sum(n))
bigrams <- left_join(bigram_count, bigram_total)
bigram_tf_idf <- bigrams %>%
bind_tf_idf(bigram, Document.ID, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
str(bigram_tf_idf)
test <- bigram_tf_idf %>%
filter(total > 8000)
test <- bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf))
test <- bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
test <- bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 1, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(bigram, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 4000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(bigram, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 6000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(bigram, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 6000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(bigram, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_tf_idf %>%
filter(total > 7000) %>%
arrange(desc(tf_idf)) %>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram))))%>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(bigram, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
bigram_total <- bigram_count %>%
group_by(bigram) %>%
summarize(total = sum(n))
View(bigram_total)
bigram_total <- bigram_count %>%
group_by(bigram) %>%
summarize(total = sum(n)) %>%
arrange(desc(total))
View(bigram_total)
View(bigram_tf_idf)
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE)
test <- commentsDf %>%
group_by(Document.ID) %>%
mutate(linenumber = row_number()) %>%
ungroup()
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE)
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 100)
install.packages("igraph", lib="C:/R/Packages")
library(igraph)
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 100)
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 200)
bigram_count <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 300) %>%
graph_from_data_frame()
install.packages("ggraph", lib="C:/R/Packages")
library(ggraph)
set.seed(2017)
bigram_graph <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 250) %>%
graph_from_data_frame()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)
bigram_graph <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 300) %>%
graph_from_data_frame()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)
bigram_graph <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 400) %>%
graph_from_data_frame()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.03, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
a <- grid::arrow(type = "closed", length = unit(.05, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
bigram_graph <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 500) %>%
graph_from_data_frame()
a <- grid::arrow(type = "closed", length = unit(.05, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
bigram_graph <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 700) %>%
graph_from_data_frame()
a <- grid::arrow(type = "closed", length = unit(.05, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
bigram_graph <- test %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
count(word1, word2, sort = TRUE) %>%
filter(n > 1000) %>%
graph_from_data_frame()
a <- grid::arrow(type = "closed", length = unit(.05, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
a <- grid::arrow(type = "closed", length = unit(.1, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.01, 'inches')) +
geom_node_point(color = "lightblue", size = 3) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
test <- commentsDf %>%
group_by(Document.ID) %>%
mutate(linenumber = row_number()) %>%
ungroup()
test1 <- test %>%
unnest_tokens(word, Text)
test1 <- test1 %>%
anti_join(stop_words)
cms_stop <- data.frame(word = c("cms","medicare","ma", "plan", "care", "beneficiaries", "advantage", "proposed", "rule", "health", "plans"), stringsAsFactors = FALSE)
test1 <- test1 %>%
anti_join(cms_stop)
test1 <- test %>%
unnest_tokens(word, Text)
test1 <- test1 %>%
anti_join(stop_words)
word_cors <- test1 %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, section, sort = TRUE)
library(widyr)
install.packages("widyr", lib="C:/R/Packages")
library(widyr)
word_cors <- test1 %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, section, sort = TRUE)
word_cors <- test1 %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, Document.ID, sort = TRUE)
View(word_cors)
word_cors <- test1 %>%
group_by(word) %>%
filter(n() >= 100) %>%
pairwise_cor(word, Document.ID, sort = TRUE)
head(word_cors)
word_cors %>%
filter(item1 %in% c("drug", "dir", "pharmacy", "pbm")) %>%
group_by(item1) %>%
top_n(6) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
word_cors %>%
filter(item1 %in% c("drug", "dir", "pharmacy", "pbm")) %>%
group_by(item1) %>%
top_n(10) %>%
ungroup() %>%
mutate(item2 = reorder(item2, correlation)) %>%
ggplot(aes(item2, correlation)) +
geom_bar(stat = "identity") +
facet_wrap(~ item1, scales = "free") +
coord_flip()
View(test1)
?cast_dtm
word_count <- test1 %>%
count(Document.ID, word, sort = TRUE) %>%
ungroup()
word_total <- word_count %>%
group_by(Document.ID) %>%
summarize(total = sum(n))
words <- left_join(word_count, word_total)
words_tf_idf <- words %>%
bind_tf_idf(word, Document.ID, n)
testing <- words_tf_idf %>%
filter(total > 8000) %>%
count(Document.ID)
words_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
View(words_tf_idf)
library(tm)
words_dtm <- cast_dtm(words_tf_idf, document = Document.ID, term = word, value = tf_idf)
View(words_dtm)
class(words_dtm)
words_dtm
install.packages("tm.plugin.webmining", lib="C:/R/Packages")
install.packages("purrr", lib="C:/R/Packages")
install.packages("purrr", lib="C:/R/Packages")
library(tm.plugin.webmining)
install.packages('rJava', lib="C:/R/Packages")
