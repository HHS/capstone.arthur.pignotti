union_all(select(commentsDf, Document.ID, Text)) %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
count(word, sort = TRUE) %>%
filter(n/length(unique(commentsDf$Comment.ID)) > .08)
bigram <- baselineDoc_section %>%
select(Document.ID, Text) %>%
union_all(select(commentsDf, Document.ID, Text)) %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
select(-Document.ID) %>%
count(word, sort = TRUE) %>%
filter(n/length(unique(commentsDf$Comment.ID)) > .08)
bigram <- baselineDoc_section %>%
select(Document.ID, Text) %>%
union_all(select(commentsDf, Document.ID, Text)) %>%
ungroup() %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
select(-Document.ID) %>%
count(word, sort = TRUE) %>%
filter(n/length(unique(commentsDf$Comment.ID)) > .08)
bigram_index <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
#    select(Document.ID, bigram) %>%
#    rbind((unnest_tokens(commentsDf, bigram, Text, token = "ngrams", n = 2) %>%
#              select(Document.ID, bigram))) %>%
rowid_to_column("index1") %>%
inner_join(bigram, by = c("bigram" = "word"))
bigram_index <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
rowid_to_column("index1") %>%
inner_join(bigram, by = c("bigram" = "word")) %>%
mutate(index2 = index1 + 1) %>%
select(Document.ID.x, bigram, index1, index2)
bigram_index <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
rowid_to_column("index1") %>%
inner_join(bigram, by = c("bigram" = "word")) %>%
mutate(index2 = index1 + 1) %>%
select(Document.ID, bigram, index1, index2)
baseline_unigram <- baselineDoc_section %>%
unnest_tokens(word, Text) %>%
rowid_to_column("index") %>%
anti_join(stop_words) %>%
anti_join(cms_stop) %>%
anti_join(bigram_index, by = c("index" = "index1")) %>%
anti_join(bigram_index, by = c("index" = "index2")) %>%
mutate(word = wordStem(word))
View(baseline_unigram)
baseline_bigram <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
filter(word %in% bigram$word)
baseline <- union_all(baseline_unigram, baseline_bigram)
View(baseline)
baseline_bigram <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
rowid_to_column("index") %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
filter(word %in% bigram$word)
baseline <- union_all(baseline_unigram, baseline_bigram)
base_count <- baseline %>%
group_by(section) %>%
count(section, word, sort = TRUE) %>%
ungroup()
base_total <- base_count %>%
group_by(section) %>%
summarize(total = sum(n))
base <- left_join(base_count, base_total) %>%
filter(total > 5)
base_tf_idf <- base %>%
bind_tf_idf(word, section, n)
base_dtm <- cast_dtm(base_tf_idf, section, word, n)
base_lda <- LDA(base_dtm,
k = length(unique(base$section)),
control = list(seed = 1234))
base_topics <- tidy(base_lda, matrix = "beta")
base_doc_topics <- tidy(base_lda, matrix = "gamma")
write.csv(base_topics, file="modelingtopicstest.csv", row.names = FALSE)
write.csv(base_doc_topics, file="modelingtest.csv", row.names = FALSE)
model_top_terms <- base_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta) %>%
inner_join(topic_map)
topic_map1 <- base_doc_topics %>%
group_by(document) %>%
filter(gamma == max(gamma))
topic_map2 <- base_doc_topics %>%
group_by(topic) %>%
filter(gamma == max(gamma))
topic_map <- rbind(topic_map1, topic_map2) %>%
distinct() %>%
select(-gamma)
model_top_terms <- base_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta) %>%
inner_join(topic_map)
model_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
model_top_terms %>%
filter(topic %in% c(1,2,3,4,5,6))
model_top_terms %>%
filter(topic %in% c(1,2,3,4,5,6)) %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
View(model_top_terms)
model_top_terms %>%
filter(topic %in% c(1,2,3,4,5,6)) %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ document, scales = "free") +
coord_flip()
model_top_terms %>%
filter(topic %in% c(61, 6, 55, 67)) %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ document, scales = "free") +
coord_flip()
multi <- base_doc_topics %>%
filter(gamma > .001) %>%
group_by(topic) %>%
count() %>%
filter(n > 1)
View(multi)
multi <- base_doc_topics %>%
filter(gamma > .01) %>%
group_by(topic) %>%
count() %>%
filter(n > 1)
model_top_terms %>%
filter(topic %in% c(61, 6, 55, 67, 13)) %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ document, scales = "free") +
coord_flip()
View(topic_map)
topic_map <- rbind(topic_map1, topic_map2) %>%
distinct() %>%
select(gamma)
#### Create Topic Map ####
topic_map1 <- base_doc_topics %>%
group_by(document) %>%
filter(gamma == max(gamma))
topic_map2 <- base_doc_topics %>%
group_by(topic) %>%
filter(gamma == max(gamma))
topic_map <- rbind(topic_map1, topic_map2) %>%
distinct() %>%
select(gamma)
topic_map <- union_all(topic_map1, topic_map2) %>%
distinct() %>%
select(gamma)
topic_map <- union_all(topic_map1, topic_map2) %>%
distinct()
View(topic_map)
base_lda <- LDA(base_dtm,
k = 75,
control = list(seed = 1234))
base_topics <- tidy(base_lda, matrix = "beta")
base_doc_topics <- tidy(base_lda, matrix = "gamma")
topic_map1 <- base_doc_topics %>%
group_by(document) %>%
filter(gamma == max(gamma))
topic_map2 <- base_doc_topics %>%
group_by(topic) %>%
filter(gamma == max(gamma))
topic_map <- union_all(topic_map1, topic_map2) %>%
distinct()
multi <- base_doc_topics %>%
filter(gamma > .01) %>%
group_by(topic) %>%
count() %>%
filter(n > 1)
View(multi)
base_lda <- LDA(base_dtm,
k = 70,
control = list(seed = 1234))
base_topics <- tidy(base_lda, matrix = "beta")
base_doc_topics <- tidy(base_lda, matrix = "gamma")
topic_map1 <- base_doc_topics %>%
group_by(document) %>%
filter(gamma == max(gamma))
topic_map2 <- base_doc_topics %>%
group_by(topic) %>%
filter(gamma == max(gamma))
topic_map <- union_all(topic_map1, topic_map2) %>%
distinct()
model_top_terms %>%
filter(topic %in% c(1,2,3,4,5,6)) %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ document, scales = "free") +
coord_flip()
#Load stop words
data(stop_words)
#Load CMS-specific stop words
cms_stop <- read_csv("Data/cms_stop_words.csv")
# Remove non-alpha-numeric characters
baselineDoc$Text <- gsub("[^A-z0-9 ]", "", baselineDoc$Text)
baselineDoc_section <- baselineDoc %>%
group_by(Document.ID) %>%
filter(Text != "",
Paragraph.Number >= baseStart) %>%
mutate(section = ifelse(str_detect(Text, regex("^section [A-Z]", ignore_case = TRUE)), Text, NA)) %>%
#    mutate(section = cumsum(str_detect(Text, regex("^section [A-Z]", ignore_case = TRUE)))) %>%
filter(str_count(Text, regex("[A-z]", ignore_case = TRUE))/str_count(Text, regex("[A-z0-9]", ignore_case = TRUE)) > .5) %>% # Removes lines that are 50% or more numbers
fill(section) %>%
filter(!is.na(section))
baselineDoc_section <- baselineDoc_section %>%
filter(Paragraph.Number < 626 | Paragraph.Number > 695)
bigram <- baselineDoc_section %>%
select(Document.ID, Text) %>%
union_all(select(commentsDf, Document.ID, Text)) %>%
ungroup() %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
select(-Document.ID) %>%
count(word, sort = TRUE) %>%
filter(n/length(unique(commentsDf$Comment.ID)) > .08)
bigram_index <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
rowid_to_column("index1") %>%
inner_join(bigram, by = c("bigram" = "word")) %>%
mutate(index2 = index1 + 1) %>%
select(Document.ID, bigram, index1, index2)
baseline_unigram <- baselineDoc_section %>%
unnest_tokens(word, Text) %>%
rowid_to_column("index") %>%
anti_join(stop_words) %>%
anti_join(cms_stop) %>%
anti_join(bigram_index, by = c("index" = "index1")) %>%
anti_join(bigram_index, by = c("index" = "index2")) %>%
mutate(word = wordStem(word))
baseline_bigram <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
rowid_to_column("index") %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
filter(word %in% bigram$word)
baseline <- union_all(baseline_unigram, baseline_bigram)
base_count <- baseline %>%
group_by(section) %>%
count(section, word, sort = TRUE) %>%
ungroup()
base_total <- base_count %>%
group_by(section) %>%
summarize(total = sum(n))
base <- left_join(base_count, base_total) %>%
filter(total > 5)
base_tf_idf <- base %>%
bind_tf_idf(word, section, n)
base_dtm <- cast_dtm(base_tf_idf, section, word, n)
length(unique(base$section))
base_lda <- LDA(base_dtm,
k = 70,
control = list(seed = 1234))
base_topics <- tidy(base_lda, matrix = "beta")
base_doc_topics <- tidy(base_lda, matrix = "gamma")
topic_map1 <- base_doc_topics %>%
group_by(document) %>%
filter(gamma == max(gamma))
topic_map2 <- base_doc_topics %>%
group_by(topic) %>%
filter(gamma == max(gamma))
topic_map <- union_all(topic_map1, topic_map2) %>%
distinct()
model_top_terms <- base_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta) %>%
inner_join(topic_map)
model_top_terms %>%
filter(topic %in% c(1,2,3,4,5,6)) %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ document, scales = "free") +
coord_flip()
baseline_unigram <- baselineDoc_section %>%
unnest_tokens(word, Text) %>%
rowid_to_column("index") %>%
filter(!(str_detect(word, regex("^http"))),
!(str_detect(word, regex("^www")))) %>%
anti_join(stop_words) %>%
anti_join(cms_stop) %>%
anti_join(bigram_index, by = c("index" = "index1")) %>%
anti_join(bigram_index, by = c("index" = "index2")) %>%
mutate(word = wordStem(word))
baseline_bigram <- baselineDoc_section %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
rowid_to_column("index") %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
filter(word %in% bigram$word)
baseline <- union_all(baseline_unigram, baseline_bigram)
base_count <- baseline %>%
group_by(section) %>%
count(section, word, sort = TRUE) %>%
ungroup()
base_total <- base_count %>%
group_by(section) %>%
summarize(total = sum(n))
base <- left_join(base_count, base_total) %>%
filter(total > 5)
base_tf_idf <- base %>%
bind_tf_idf(word, section, n)
base_dtm <- cast_dtm(base_tf_idf, section, word, n)
base_lda <- LDA(base_dtm,
k = 70,
control = list(seed = 1234))
save(base_lda, file = "Models/lda_test.rda")
base_topics <- tidy(base_lda, matrix = "beta")
base_doc_topics <- tidy(base_lda, matrix = "gamma")
write.csv(base_topics, file="modelingtopicstest.csv", row.names = FALSE)
write.csv(base_doc_topics, file="modelingtest.csv", row.names = FALSE)
write.csv(base_topics, file="modelingtopicstest.csv", row.names = FALSE)
write.csv(base_topics, file="modelingtopicstest.csv", row.names = FALSE)
write.csv(base_doc_topics, file="modelingtest.csv", row.names = FALSE)
comment.words <- commentsDf %>%
unnest_tokens(word, Text) %>%
anti_join(stop_words) %>%
anti_join(cms_stop) %>%
filter(!(str_detect(word, regex("^http"))),
!(str_detect(word, regex("^www")))) %>%
mutate(word = wordStem(word))
comment.bigrams <- commentsDf %>%
unnest_tokens(bigram, Text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
anti_join(stop_words, by = c("word1" = "word")) %>%
anti_join(stop_words, by = c("word2" = "word")) %>%
anti_join(cms_stop, by = c("word1" = "word")) %>%
anti_join(cms_stop, by = c("word2" = "word")) %>%
filter(!(str_detect(word1, regex("^http"))),
!(str_detect(word1, regex("^www"))),
!(str_detect(word2, regex("^http"))),
!(str_detect(word2, regex("^www")))) %>%
mutate(word1 = wordStem(word1),
word2 = wordStem(word2)) %>%
unite(word, word1, word2, sep = " ") %>%
filter(word %in% bigram$word)
comments <- union(comment.words, comment.bigrams)
#### TF-IDF Testing ####
word_count <- comments %>%
count(Document.ID, word, sort = TRUE) %>%
ungroup()
word_total <- word_count %>%
group_by(Document.ID) %>%
summarize(total = sum(n))
words <- left_join(word_count, word_total)
words_tf_idf <- words %>%
bind_tf_idf(word, Document.ID, n)
words_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 3, scales = "free") +
coord_flip()
words_dtm_tf_idf <- cast_dtm(words_tf_idf, document = Document.ID, term = word, value = tf_idf)
words_dtm <- cast_dtm(word_count, document = Document.ID, term = word, value = n)
words_dtm.topics <- posterior(base_lda, words_dtm)
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:80) %>%
mutate(Topic = as.numeric(Topic))
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics))
View(words_scoring)
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
transmute(Topic = as.numeric(Topic))
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic))
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic"))
ungroup()
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic")) %>%
mutate(final_score = Score * gamma) %>%
group_by(Document.ID, document) %>%
summarise(score = sum(finalscore)) %>%
arrange(-gamma) %>%
ungroup()
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic")) %>%
mutate(final_score = Score * gamma)
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic")) %>%
mutate(final_score = as.numeric(Score) * gamma)
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic")) %>%
mutate(final_score = as.numeric(Score) * gamma) %>%
group_by(Document.ID, document) %>%
summarise(score = sum(finalscore)) %>%
arrange(-gamma) %>%
ungroup()
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic")) %>%
mutate(final_score = as.numeric(Score) * gamma) %>%
group_by(Document.ID, document) %>%
summarise(sum = sum(finalscore)) %>%
arrange(-sum) %>%
ungroup()
words_scoring <- as.data.frame(cbind(Document.ID = rownames(words_dtm.topics$topics),
words_dtm.topics$topics)) %>%
gather(key = "Topic", value = "Score", 2:71) %>%
mutate(Topic = as.numeric(Topic)) %>%
right_join(base_doc_topics, by = c("Topic" = "topic")) %>%
mutate(final_score = as.numeric(Score) * gamma) %>%
group_by(Document.ID, document) %>%
summarise(sum = sum(final_score)) %>%
arrange(-sum) %>%
ungroup()
View(words)
View(commentsDf)
