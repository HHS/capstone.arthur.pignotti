.libPaths( c("C:/R/Packages", .libPaths()) )
setwd("C:/Users/P6BQ/Desktop/DSCoLab-Spring-2018-Cohort-Material/data")
setwd("C:/Users/P6BQ/Desktop/capstone.arthur.pignotti") #local location of github repo
dktid = "CMS-2017-0163"
#libraries
library(tm)
library(readxl)
library(tidyverse)
comLoc <- "C:/Data/Comments/Testing"
#Comment Report from FDMS
comReport <- read_excel(paste0(comLoc, "/report.xlsx"), sheet = 1)
colnames(comReport) <- make.names(colnames(comReport))
#Comment Report from FDMS
attReport <- read_excel(paste0(comLoc, "/report.xlsx"), sheet = 2)
colnames(attReport) <- make.names(colnames(attReport))
#Comment Dataset from Data_Download.R
comments <- read_csv("Data/comments.csv")
#Map of Comments, Commenters, Commenter Categories
map <- read_excel(paste0(comLoc, "/map.xlsx"))
colnames(map) <- make.names(colnames(map))
#Text Extract of Comment Attachments
attachExtract <- read_excel("Data/CMS-2017-0156-TExtract.xlsx")
colnames(attachExtract) <- make.names(colnames(attachExtract))
comReport$Site_Key <- substring(comReport$Email.Address, regexpr("@", comReport$Email.Address) + 1)
attachExtract <- attachExtract %>%
mutate(Comment.ID = substr(File.Name,1,18),
Document.ID = substr(File.Name, 1, regexpr("\\.", File.Name) - 1)) %>%
select(Comment.ID, Document.ID, Text, Page.Number) %>%
left_join(comReport, by = c("Comment.ID" = "Document.ID")) %>%
left_join(map, by = c("Comment.ID" = "Document"))
commentsDf <- comments %>%
mutate(Document.ID = paste0(documentId, "-0"),
Comment.ID = documentId,
Text = commentText,
Page.Number = 1) %>%
select(Comment.ID, Document.ID, Text, Page.Number) %>%
left_join(comReport, by = c("Comment.ID" = "Document.ID")) %>%
left_join(map, by = c("Comment.ID" = "Document")) %>%
union(attachExtract)
write.csv(commentsDf, file = "Data/commentsDf.csv")
?write.csvg
?write.csv
write.csv(commentsDf, file = "Data/commentsDf.csv", row.names = FALSE)
install.packages("hunspell", lib="C:/R/Packages")
library(hunspell)
test <- hunspell_find(commentsDf$Text)
test <- count(test)
test1 <- count(as.data.frame(test))
test1 <- as.data.frame(test)
test1 <- unique(test)
View(test1)
test1[[102]]
commentsDf <- read.csv("Data/commentsDf.csv")
library(dplyr)
library(stringr)
library(ggplot2)
library(tidytext)
library(tidyr)
data(stop_words)
test <- commentsDf %>%
group_by(Document.ID) %>%
mutate(linenumber = row_number()) %>%
ungroup()
test1 <- test %>%
unnest_tokens(word, Text)
commentsDf <- read.csv("Data/commentsDf.csv", stringsAsFactors = False)
commentsDf <- read.csv("Data/commentsDf.csv", stringsAsFactors = FALSE)
test <- commentsDf %>%
group_by(Document.ID) %>%
mutate(linenumber = row_number()) %>%
ungroup()
test1 <- test %>%
unnest_tokens(word, Text)
test1 <- test1 %>%
anti_join(stop_words)
cms_stop <- data.frame(word = c("cms","medicare","ma", "plan", "care", "beneficiaries", "advantage", "proposed", "rule", "health", "plans"), stringsAsFactors = FALSE)
test1 <- test1 %>%
anti_join(cms_stop)
View(test1)
spell.test <- hunspell_find(test1$Word)
spell.test <- hunspell_find(test1$word)
str(spell.test)
spell.test1 <- unique(spell.test)
spell.count <- as.data.frame(spell.test1)
View(spell.test1)
#######################
# TF-IDF Testing      #
#######################
word_count <- test1 %>%
count(Document.ID, word, sort = TRUE) %>%
ungroup()
word_total <- test1 %>%
group_by(Document.ID) %>%
summarize(total = sum(n))
word_total <- word_count %>%
group_by(Document.ID) %>%
summarize(total = sum(n))
words <- left_join(word_count, word_total)
words_tf_idf <- words %>%
bind_tf_idf(word, Document.ID, n)
View(words_tf_idf)
words_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
testing <- words_tf_idf %>%
filter(total > 40000)
testing <- words_tf_idf %>%
filter(total > 20000)
testing <- words_tf_idf %>%
filter(total > 30000)
testing <- words_tf_idf %>%
filter(total > 35000)
View(testing)
count()
count(word)
testing <- words_tf_idf %>%
filter(total > 35000) %>%
group_by(Document.ID) %>%
count(word)
View(testing)
View(words_tf_idf)
testing <- words_tf_idf %>%
filter(total > 35000) %>%
unique(Document.ID)
View(words_tf_idf)
testing <- words_tf_idf %>%
filter(total > 35000) %>%
unique(Document.ID)
testing <- words_tf_idf %>%
filter(total > 3000) %>%
unique(Document.ID)
testing <- words_tf_idf %>%
filter(total > 20000) %>%
unique(.$Document.ID)
testing <- words_tf_idf %>%
filter(total > 20000) %>%
distinct_n(Document.ID)
testing <- words_tf_idf %>%
filter(total > 20000) %>%
count(Document.ID, word)
View(testing)
testing <- words_tf_idf %>%
filter(total > 20000) %>%
count(Document.ID)
testing <- words_tf_idf %>%
filter(total > 10000) %>%
count(Document.ID)
words_tf_idf %>%
filter(total > 10000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
View(stop_words)
View(commentsDf)
testing <- words_tf_idf %>%
filter(total > 9000) %>%
count(Document.ID)
testing <- words_tf_idf %>%
filter(total > 8000) %>%
count(Document.ID)
words_tf_idf %>%
filter(total > 10000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
words_tf_idf %>%
filter(total > 8000) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(Document.ID) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = Document.ID)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~Document.ID, ncol = 2, scales = "free") +
coord_flip()
